{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wedge Project\n",
    "## Intial Setup\n",
    "\n",
    "Loading in the clean files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transArchive_201210_201212_inactive_clean.csv',\n",
       " 'transArchive_201010_201012_clean.csv',\n",
       " 'transArchive_201601_clean.csv',\n",
       " 'transArchive_201107_201109_clean.csv',\n",
       " 'transArchive_201310_201312_inactive_clean.csv',\n",
       " 'transArchive_201204_201206_clean.csv',\n",
       " 'transArchive_201104_clean.csv',\n",
       " 'transArchive_201512_clean.csv',\n",
       " 'transArchive_201307_201309_clean.csv',\n",
       " 'transArchive_201210_201212_clean.csv',\n",
       " 'transArchive_201410_201412_inactive_clean.csv',\n",
       " 'transArchive_201004_201006_clean.csv',\n",
       " 'transArchive_201307_201309_inactive_clean.csv',\n",
       " 'transArchive_201207_201209_inactive_clean.csv',\n",
       " 'transArchive_201410_201412_clean.csv',\n",
       " 'transArchive_201607_clean.csv',\n",
       " 'transArchive_201507_201509_clean.csv',\n",
       " 'transArchive_201407_201409_inactive_clean.csv',\n",
       " 'transArchive_201404_201406_clean.csv',\n",
       " 'transArchive_201207_201209_clean.csv',\n",
       " 'transArchive_201310_201312_clean.csv',\n",
       " 'transArchive_201304_201306_inactive_clean.csv',\n",
       " 'transArchive_201204_201206_inactive_clean.csv',\n",
       " 'transArchive_201110_201112_clean.csv',\n",
       " 'transArchive_201105_clean.csv',\n",
       " 'transArchive_201007_201009_clean.csv',\n",
       " 'transArchive_201304_201306_clean.csv',\n",
       " 'transArchive_201404_201406_inactive_clean.csv',\n",
       " 'transArchive_201504_201506_clean.csv',\n",
       " 'transArchive_201401_201403_inactive_clean.csv',\n",
       " 'transArchive_201606_clean.csv',\n",
       " 'transArchive_201612_clean.csv',\n",
       " 'transArchive_201301_201303_inactive_clean.csv',\n",
       " 'transArchive_201201_201203_inactive_clean.csv',\n",
       " 'transArchive_201407_201409_clean.csv',\n",
       " 'transArchive_201001_201003_clean.csv',\n",
       " 'transArchive_201603_clean.csv',\n",
       " 'transArchive_201201_201203_clean.csv',\n",
       " 'transArchive_201106_clean.csv',\n",
       " 'transArchive_201510_clean.csv',\n",
       " 'transArchive_201611_clean.csv',\n",
       " 'transArchive_201605_clean.csv',\n",
       " 'transArchive_201401_201403_clean.csv',\n",
       " 'transArchive_201608_clean.csv',\n",
       " 'transArchive_201701_clean.csv',\n",
       " 'transArchive_201301_201303_clean.csv',\n",
       " 'transArchive_201602_clean.csv',\n",
       " 'transArchive_201511_clean.csv',\n",
       " 'transArchive_201101_201103_clean.csv',\n",
       " 'transArchive_201604_clean.csv',\n",
       " 'transArchive_201610_clean.csv',\n",
       " 'transArchive_201609_clean.csv',\n",
       " 'transArchive_201501_201503_clean.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"clean-files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_files = os.listdir(\"clean-files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I'm going to establish Connection with GBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do our imports for the code\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These first two values will be different on your machine. \n",
    "service_path = \"/Users/CJMcWilliams/Desktop/ADA/Wedge/\"\n",
    "service_file = 'Wedge Project-1575e46935c4.json' # change this to your authentication information  \n",
    "gbq_proj_id = 'disco-beach-290522' # change this to your poroject. \n",
    "gbq_dataset_id = 'wedge' # and change this to your data set ID\n",
    "\n",
    "private_key =service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And create a client to talk to GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to clean files\n",
    "path_to_files = \"/Users/CJMcWilliams/Desktop/ADA/Wedge/Project/clean-files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Creation\n",
    "\n",
    "\n",
    "Next is where I create a table for each file in the folder. This also includes adding a schema to our tables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see if the table exists\n",
    "def tbl_exists(client, table_ref):\n",
    "    from google.cloud.exceptions import NotFound\n",
    "    try:\n",
    "        client.get_table(table_ref)\n",
    "        return True\n",
    "    except NotFound:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beginning code that allows us to modify the table\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "job_config.schema_update_options = [\n",
    "    bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION # This allows us to modify the table. \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema field additions for tables\n",
    "job_config.schema = [\n",
    "    bigquery.SchemaField(\"datetime\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"register_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"emp_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"upc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_subtype\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_status\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"department\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"quantity\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Scale\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cost\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"unitPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"total\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"regPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"altPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tax\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"taxexempt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"foodstamp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"wicable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memDiscount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discountable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discounttype\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"voided\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"percentDiscount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ItemQtty\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volDiscType\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volume\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"VolSpecial\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mixMatch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"matched\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memType\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"staff\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"numflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"itemstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tenderstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"charflag\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"varflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"batchHeaderID\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"local\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"organic\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"display\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"receipt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"card_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"store\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"branch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"match_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "]\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table transArchive_201501_201503 contains 0 columns\n",
      "Loaded 3041128 rows into wedge_example:transArchive_201501_201503.\n",
      "Table transArchive_201501_201503 now contains 50 columns.\n"
     ]
    }
   ],
   "source": [
    "#open the files and loading them into seperate tables in GBQ\n",
    "\n",
    "for file in clean_files:\n",
    "    my_table,junk = file.split(\"_clean\")#splits on _clean in csv files and removes rest as junk\n",
    "    table_full_name = \".\".join([gbq_proj_id,gbq_dataset_id,my_table]) #creates GBQ table name\n",
    "    \n",
    "    if not tbl_exists(client, table_full_name) :\n",
    "        table_ref = client.create_table(table = table_full_name)\n",
    "    else :\n",
    "        table_ref = client.get_table(table_full_name)\n",
    "    \n",
    "    table = client.get_table(table_ref)\n",
    "    print(\"Table {} contains {} columns\".format(table_ref.table_id,len(table.schema)))\n",
    "    \n",
    "    with open(path_to_files + file, \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(\n",
    "            source_file,\n",
    "            table_ref,\n",
    "            location=\"US\",  # Must match the destination dataset location.\n",
    "            job_config=job_config,\n",
    "        )  # API request\n",
    "\n",
    "    job.result()  # Waits for table load to complete.\n",
    "    print(\"Loaded {} rows into {}:{}.\".format(job.output_rows, 'wedge_example', table_ref.table_id))\n",
    "\n",
    "    # Checks the updated length of the schema\n",
    "    table = client.get_table(table)\n",
    "    print(\"Table {} now contains {} columns.\".format(table_ref.table_id, len(table.schema)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "In Part 2 of the Wedge Project, the objectives are to:\n",
    "    - Build a list of owners \n",
    "    - Take a sample of the owners \n",
    "    - Extracts all records associated with those owners and writes them to a local text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connects with GBQ\n",
    "service_path = \"/Users/CJMcWilliams/Desktop/ADA/Wedge/\"\n",
    "service_file = 'Wedge Project-1575e46935c4.json' # change this to your authentication information  \n",
    "gbq_proj_id = 'disco-beach-290522' # change this to your poroject. \n",
    "gbq_dataset_id = 'wedge' # and change this to your data set ID\n",
    "\n",
    "private_key =service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And create a client to talk to GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query selecting each individual card_no (distinct) while leaving out card_no=3 (non members)\n",
    "query = \"Select Distinct card_no,\" \"From `disco-beach-290522.wedge.transArchive*`\" \"Where card_no !=3\"\n",
    "\n",
    "#execute the query using 'client.query'\n",
    "query_job = client.query(query,location ='US',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a list of all the owners\n",
    "owners = []\n",
    "\n",
    "for idx, row in enumerate(query_job) :\n",
    "    card_no = row[0] #since row in GBQ is a tuple you need to place[]\n",
    "    \n",
    "    owners.append(card_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of random owners\n",
    "random.seed(101010) #start random generator at the same spot\n",
    "owner_sample = random.choices(owners,k=401) #random list of owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query selecting card numbers\n",
    "query = \"\"\"Select * From `disco-beach-290522.wedge.transArchive*` Where card_no in (\"\"\"\n",
    "\n",
    "query = query + \",\".join([str(owner) for owner in owner_sample]) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(query,location ='US',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header names\n",
    "headers = [\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to do the \"join\"\n",
    "#query = for owner in owner_sample : query = query[:-1] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the files as txt file and add headers to the first row\n",
    "with open (\"owner_query.txt\", \"w\") as outfile :\n",
    "    outfile.write (\",\".join(headers) + \"\\n\")\n",
    "    for row in query_job:\n",
    "        outfile.write(\",\".join([str(item) for item in row]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "In Part 3 of the Wedge Project, I will build a single SQLite database via Python (in a .db file) containing the three following tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connects with GBQ\n",
    "service_path = \"/Users/CJMcWilliams/Desktop/ADA/Wedge/\"\n",
    "service_file = 'Wedge Project-1575e46935c4.json' # change this to your authentication information  \n",
    "gbq_proj_id = 'disco-beach-290522' # change this to your poroject. \n",
    "gbq_dataset_id = 'wedge' # and change this to your data set ID\n",
    "\n",
    "private_key =service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And create a client to talk to GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Sales by Date by Hour \n",
    "The first table to be created is Sales by date by hour:\n",
    "\n",
    "By calendar date (YYYY-MM-DD) and hour of the day, determine the total spend in the store, the number of transactions, and a count of the number of items . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing out the query\n",
    "#query for SALES by DATE by HOUR\n",
    "query = (\"SELECT (EXTRACT(date FROM datetime)) AS Date, \" \n",
    "\"(EXTRACT(hour FROM datetime)) AS Hour, \" \n",
    "\"SUM(total) AS Sales, \" \n",
    "\"COUNT(DISTINCT(Date(datetime) || register_no || emp_no || trans_no)) AS Transactions, \" \n",
    "\"SUM(CASE WHEN(trans_status = 'V' OR trans_status = 'R') THEN -1 ELSE 1 END) as Items \"  \n",
    "\"FROM `disco-beach-290522.wedge.transArchive*` \" \n",
    "\"WHERE card_no != 3 \" \n",
    "\"AND department != 0 \" \n",
    "\"AND department != 15 \" \n",
    "\"AND trans_status != 'M' \" \n",
    "\"AND trans_status != 'C' \" \n",
    "\"AND trans_status != 'J' \" \n",
    "\"AND (trans_status = '' \" \n",
    "\"OR trans_status = ' ' \" \n",
    "\"OR trans_status =  'V' \" \n",
    "\"OR trans_status = 'R') \" \n",
    "\"GROUP BY Date, Hour \" \n",
    "\"ORDER BY Date, Hour \")\n",
    "\n",
    "#execute the query using 'client.query'\n",
    "query_job = client.query(query,location ='US',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = [\"date\",\"hour\",\"sales\",\"transactions\",\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change name, write out to a .txt file, CHANGE headers\n",
    "with open (\"Table 1: SALES by DATE by HOUR.txt\", \"w\") as outfile :\n",
    "    outfile.write (\",\".join(head) + \"\\n\")\n",
    "    for row in query_job:\n",
    "        outfile.write(\",\".join([str(item) for item in row]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a database\n",
    "db = sqlite3.connect(\"wedge_project.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a way to talk to the database\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving table as variable that will be used to load into database\n",
    "input_file = \"Table 1: SALES by DATE by HOUR.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates new blank table with headers\n",
    "cur.execute('''DROP TABLE IF EXISTS table1''')\n",
    "cur.execute('''CREATE TABLE table1 (\n",
    "    date TIMESTAMP, \n",
    "    hour INTEGER, \n",
    "    sales INTEGER,\n",
    "    transactions INTEGER,\n",
    "    items INTEGER)''')\n",
    "\n",
    "#actually loading the data into the table in the database\n",
    "with open(input_file,'r', encoding=\"Latin-1\") as ifile :\n",
    "    next(ifile) #skips headers\n",
    "    for idx, line in enumerate(ifile.readlines()) :\n",
    "        line = line.strip().split(\",\")\n",
    "        cur.execute('''\n",
    "            INSERT INTO table1 (date,hour,sales,transactions,items)\n",
    "            VALUES (?,?,?,?,?)''', line)\n",
    "\n",
    "        #if idx > 100 :\n",
    "            #break\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Sales by Owner by Year\n",
    "The second table to be created is Sales by owner by year by month: \n",
    "\n",
    "A file that has the following columns: card_no, year, month, sales, transactions, and items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing out the query\n",
    "#query for SALES by DATE by HOUR\n",
    "query = ('''SELECT card_no As Owner,\n",
    "    (EXTRACT(year FROM datetime)) AS Year,\n",
    "    (EXTRACT(month FROM datetime)) AS Month,\n",
    "    SUM(total) AS Sales,\n",
    "    COUNT(DISTINCT(Date(datetime) || register_no || emp_no || trans_no)) AS Transactions,\n",
    "    SUM(CASE WHEN(trans_status = 'V' OR trans_status = 'R') THEN -1 ELSE 1 END) as Items\n",
    "    FROM `disco-beach-290522.wedge.transArchive*`\n",
    "    WHERE card_no != 3\n",
    "    AND department != 0\n",
    "    AND department != 15\n",
    "    AND trans_status != 'M'\n",
    "    AND trans_status != 'C'\n",
    "    AND trans_status != 'J'\n",
    "    AND (trans_status = ''\n",
    "    OR trans_status = ' '\n",
    "    OR trans_status =  'V'\n",
    "    OR trans_status = 'R')\n",
    "    GROUP BY Owner, Year, Month\n",
    "    ORDER BY Owner, Year, Month DESC''')\n",
    "\n",
    "#execute the query using 'client.query'\n",
    "query_job = client.query(query,location ='US',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT card_no As Owner,\\n    (EXTRACT(year FROM datetime)) AS Year,\\n    (EXTRACT(month FROM datetime)) AS Month,\\n    SUM(total) AS Sales,\\n    COUNT(DISTINCT(Date(datetime) || register_no || emp_no || trans_no)) AS Transactions,\\n    SUM(CASE WHEN(trans_status = 'V' OR trans_status = 'R') THEN -1 ELSE 1 END) as Items\\n    FROM `disco-beach-290522.wedge.transArchive*`\\n    WHERE card_no != 3\\n    AND department != 0\\n    AND department != 15\\n    AND trans_status != 'M'\\n    AND trans_status != 'C'\\n    AND trans_status != 'J'\\n    AND (trans_status = ''\\n    OR trans_status = ' '\\n    OR trans_status =  'V'\\n    OR trans_status = 'R')\\n    GROUP BY Owner, Year, Month\\n    ORDER BY Owner, Year, Month DESC\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"owner\",\"year\",\"month\",\"sales\",\"transactions\",\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change name, write out to a .txt file, CHANGE headers\n",
    "with open (\"Table 2: Sales by Owner by Year.txt\", \"w\") as outfile :\n",
    "    outfile.write (\",\".join(headers) + \"\\n\")\n",
    "    for row in query_job:\n",
    "        outfile.write(\",\".join([str(item) for item in row]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving table as variable that will be used to load into database\n",
    "input_file = \"Table 2: Sales by Owner by Year.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates new blank table with headers\n",
    "cur.execute('''DROP TABLE IF EXISTS table2''')\n",
    "cur.execute('''CREATE TABLE table2 (\n",
    "    owner INTEGER,\n",
    "    year INTEGER,\n",
    "    month INTEGER,\n",
    "    sales INTEGER,\n",
    "    transactions INTEGER,\n",
    "    items INTEGER)''')\n",
    "\n",
    "#actually loading the data into the table in the database\n",
    "with open(input_file,'r', encoding=\"Latin-1\") as ifile :\n",
    "    next(ifile) #skips headers\n",
    "    for idx, line in enumerate(ifile.readlines()) :\n",
    "        line = line.strip().split(\",\")\n",
    "        cur.execute('''\n",
    "            INSERT INTO table2 (owner,year,month,sales,transactions,items)\n",
    "            VALUES (?,?,?,?,?,?)''', line)\n",
    "\n",
    "        #if idx > 100 :\n",
    "            #break\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Sales by Product Description by Year by Month\n",
    "The third table to be created is Sales by product description by year by month: \n",
    "\n",
    "A file that has the following columns: upc, description, department number, department name, year, month, sales, transactions, and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing out the query\n",
    "#query for SALES by PRODUCT DESCRIPTION by YEAR by MONTH\n",
    "query = ('''SELECT tr.department, dl.dept_name,\n",
    "    description,\n",
    "    (EXTRACT(year FROM datetime)) AS Year,\n",
    "    (EXTRACT(month FROM datetime)) AS Month,\n",
    "    upc,\n",
    "    SUM(total) AS Sales,\n",
    "    COUNT(DISTINCT(Date(datetime) || register_no || emp_no || trans_no)) AS Transactions,\n",
    "    SUM(CASE WHEN(trans_status = 'V' OR trans_status = 'R') THEN -1 ELSE 1 END) as Items,\n",
    "    tr.department AS dept_no\n",
    "    FROM `disco-beach-290522.wedge.transArchive*` AS tr\n",
    "    LEFT OUTER JOIN `disco-beach-290522.wedge.department_lookup` AS dl ON tr.department = dl.department\n",
    "    WHERE card_no != 3\n",
    "    AND tr.department != 0 \n",
    "    AND tr.department != 15\n",
    "    AND trans_status != 'M'\n",
    "    AND trans_status != 'C'\n",
    "    AND trans_status != 'J'\n",
    "    AND (trans_status = ''\n",
    "    OR trans_status = ' '\n",
    "    OR trans_status =  'V'\n",
    "    OR trans_status = 'R')\n",
    "    GROUP BY Year, Month, upc, description, dept_no, dl.dept_name\n",
    "    ORDER BY description, Year, Month DESC''')\n",
    "\n",
    "#execute the query using 'client.query'\n",
    "query_job = client.query(query,location ='US',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Department\",\"Dept_name\",\"Description\",\"Year\",\"Month\",\"upc\",\"Sales\",\"Transactions\",\"Items\",\"dept_no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change name, write out to a .txt file, CHANGE headers\n",
    "with open (\"Table 3: Sales by Product Description by Year by Month.txt\", \"w\") as outfile :\n",
    "    outfile.write (\",\".join(headers) + \"\\n\")\n",
    "    for row in query_job:\n",
    "        outfile.write(\",\".join([str(item) for item in row]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving table as variable that will be used to load into database\n",
    "input_file = \"Table 3: Sales by Product Description by Year by Month.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates new blank table with headers\n",
    "cur.execute('''DROP TABLE IF EXISTS table3''')\n",
    "cur.execute('''CREATE TABLE table3 (\n",
    "    Department INTEGER,\n",
    "    Dept_name INTERGER,\n",
    "    Description INTERGER,\n",
    "    Year INTEGER,\n",
    "    Month INTEGER,\n",
    "    upc INTEGER,\n",
    "    Sales INTEGER,\n",
    "    Transactions INTEGER,\n",
    "    Items INTEGER,\n",
    "    dept_no INTEGER)''')\n",
    "\n",
    "#actually loading the data into the table in the database\n",
    "with open(input_file,'r', encoding=\"Latin-1\") as ifile :\n",
    "    next(ifile) #skips headers\n",
    "    for idx, line in enumerate(ifile.readlines()) :\n",
    "        line = line.strip().split(\",\")\n",
    "        cur.execute('''\n",
    "            INSERT INTO table3 (Department,Dept_name,Description,Year,Month,upc,Sales,Transactions,Items,dept_no)\n",
    "            VALUES (?,?,?,?,?,?,?,?,?,?)''', line)\n",
    "\n",
    "        #if idx > 100 :\n",
    "            #break\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wow... Finally finished!\n",
    "\n",
    "All three tables are now loaded into a SQL database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
